{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad992855",
   "metadata": {},
   "source": [
    "# Implementation of a spam finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07d40d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2bd503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> Set[str]:\n",
    "    text = text.lower()                        # Convert to lowercase,\n",
    "    all_words = re.findall(\"[a-z0-9']+\", text) # extract the words, and\n",
    "    return set(all_words)                      # remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73377f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "assert tokenize(\"Data Sience is sience\") == {\"data\", \"sience\", \"is\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97765d7",
   "metadata": {},
   "source": [
    "**Defining a type for the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3628b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Message(NamedTuple):\n",
    "    text: str\n",
    "    is_spam : bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51262c3",
   "metadata": {},
   "source": [
    "**Creating a token to keep track on how often we see each token in a spam message**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbbc8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Iterable\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayersClassifier:\n",
    "    def __init__(self, k: float = 0.5) -> None:\n",
    "        self.k = k # Smoothing factor\n",
    "        \n",
    "        self.tokens: Set[str] = set()\n",
    "        self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.spam_messages = self.ham_messages = 0\n",
    "    \n",
    "    \"\"\"\n",
    "    First increment spam_messages and ham_messages counts.\n",
    "    Tokenize each message text and increment the token_spam_counts \n",
    "    or token_ham_counts based on message types\n",
    "    \"\"\"\n",
    "    def train(self, messages: Iterable[Message]) -> None:\n",
    "        for message in messages:\n",
    "            # Increment message count\n",
    "            if message.is_spam:\n",
    "                self.spam_messages += 1\n",
    "            else:\n",
    "                self.ham_messages += 1\n",
    "        \n",
    "            # Increment the word count\n",
    "            for token in tokenize(message.text):\n",
    "                self.tokens.add(token)\n",
    "                if message.is_spam:\n",
    "                    self.token_spam_counts[token] += 1\n",
    "                else:\n",
    "                    self.token_ham_counts[token] += 1\n",
    "                    \n",
    "    def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "        \"\"\"Returns P(token | spam) and P(token | ham)\"\"\"\n",
    "        spam = self.token_spam_counts[token]\n",
    "        ham = self.token_ham_counts[token]\n",
    "    \n",
    "        p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "        p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "    \n",
    "        return p_token_spam, p_token_ham\n",
    "\n",
    "\n",
    "    def predict(self, text: str) -> float:\n",
    "        text_token = tokenize(text)\n",
    "        log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "    \n",
    "        # Iterate through each word in our vocabulary\n",
    "        for token in self.tokens:\n",
    "            prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "        \n",
    "            # If *token* appears in the message,\n",
    "            # ass the log probability of seeing it\n",
    "            if token in text_token:\n",
    "                log_prob_if_spam += math.log(prob_if_spam)\n",
    "                log_prob_if_ham += math.log(prob_if_ham)\n",
    "            \n",
    "            # Otherwise add the log probability of _not_ seeing it,\n",
    "            # which ois log(1 - probability of seeing it)\n",
    "            else:\n",
    "                log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "                log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
    "                prob_if_spam = math.exp(log_prob_if_spam)\n",
    "                prob_if_ham = math.exp(log_prob_if_ham)\n",
    "            \n",
    "                return prob_if_spam / (prob_if_spam + prob_if_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f666a",
   "metadata": {},
   "source": [
    "**Probabilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e897199",
   "metadata": {},
   "source": [
    "def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "    \"\"\"Returns P(token | spam) and P(token | ham)\"\"\"\n",
    "    spam = self.token_spam_counts[token]\n",
    "    ham = self.token_ham_counts[token]\n",
    "    \n",
    "    p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "    p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "    \n",
    "    return p_token_spam, p_token_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954fb25",
   "metadata": {},
   "source": [
    "### Now to write the predict method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df00b223",
   "metadata": {},
   "source": [
    "def predict(self, text: str) -> float:\n",
    "    text_token = tokenize(text)\n",
    "    log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "    \n",
    "    # Iterate through each word in our vocabulary\n",
    "    for token in self.tokens:\n",
    "        prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "        \n",
    "        # If *token* appears in the message,\n",
    "        # ass the log probability of seeing it\n",
    "        if token in text_token:\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            log_prob_if_ham += math.log(prob_if_ham)\n",
    "            \n",
    "        # Otherwise add the log probability of _not_ seeing it,\n",
    "        # which ois log(1 - probability of seeing it)\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
    "            prob_if_spam = math.exp(log_prob_if_spam)\n",
    "            prob_if_ham = math.exp(log_prob_if_ham)\n",
    "            \n",
    "            return prob_if_spam / (prob_if_spam + prob_if_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a470d",
   "metadata": {},
   "source": [
    "**Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff52d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [Message(\"Spam rules\", is_spam=True),\n",
    "           Message(\"ham rules\", is_spam=False),\n",
    "           Message(\"Hello ham\", is_spam=False)]\n",
    "\n",
    "model = NaiveBayersClassifier(k=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f253c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a3fcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.tokens == {\"spam\", \"ham\", \"rules\", \"hello\"}\n",
    "assert model.spam_messages == 1\n",
    "assert model.ham_messages == 2\n",
    "assert model.token_spam_counts == {\"spam\":1, \"rules\":1}\n",
    "assert model.token_ham_counts == {\"ham\" : 2, \"rules\": 1, \"hello\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a6002",
   "metadata": {},
   "source": [
    "**Let's try to make a prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b04011f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18088/2359223223.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Should be about 0.83\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mp_if_spam\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp_if_spam\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp_if_ham\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = \"hello spam\"\n",
    "\n",
    "probs_if_spam = [\n",
    "    (1 + 0.5) / (1 + 2 * 0.5),    # \"spam\" (present)\n",
    "    1 - (0 + 0.5)/ (1 + 2 * 0.5), # \"ham\" (not present)\n",
    "    1 - (1 + 0.5) / (1 + 2 * 0.5),  # \"rules\" (not present)\n",
    "    (0 + 0.5) / (1 + 2 * 0.5)     # \"hello\" (present)\n",
    "]\n",
    "\n",
    "probs_if_ham = [\n",
    "    (0 + 0.5) / (2 + 2 * 0.5),    # \"spam\" (present)\n",
    "    1 - (2 + 0.5) / (2 + 2 * 0.5),# \"ham\" (not present)\n",
    "    1 - (1 + 0.5) / (2 + 2 * 0.5),# \"rules\" (not present)\n",
    "    (1 + 0.5) / (2 + 2 * 0.5),     # \"hello\" (present)\n",
    "]\n",
    "\n",
    "p_if_spam = math.exp(sum(math.log(p) for p in probs_if_spam))\n",
    "p_if_ham = math.exp(sum(math.log(p) for p in probs_if_ham))\n",
    "\n",
    "# Should be about 0.83\n",
    "assert model.predict(text) == p_if_spam / (p_if_spam + p_if_ham)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
